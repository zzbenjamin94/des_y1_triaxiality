{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template fitting for richness-mass binned by cosi\n",
    "## Zhuowen Zhang\n",
    "### First Created April 16, 2018\n",
    "#### Updated Aug 22, 2018\n",
    "#### Nov. 16: Changed file reading for halo run catalog. read_shape_param is more flexible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import pyplot and set some parameters to make plots prettier\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.plot_utils import plot_pretty\n",
    "plot_pretty()\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/zzbenjamin94/Desktop/Astronomy/Research/DES_Galaxy_Cluster')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tools.setup.setup import tools_home_dir, home_dir\n",
    "import astropy.io.fits as fits\n",
    "shapedir = home_dir()+'output/buzzard/halo_shape/'\n",
    "tpltdir = home_dir() + 'output/lmda_cosi_chains/hrun/'\n",
    "buzzdir = home_dir() + 'output/buzzard/'\n",
    "toolsdir = tools_home_dir()\n",
    "homedir = home_dir()\n",
    "\n",
    "import astropy.io.fits as pyfits\n",
    "import ConfigParser\n",
    "import healpy as hp\n",
    "import treecorr\n",
    "import os\n",
    "\n",
    "from repo.halo_shape.halo_shape_stats_backend import kmeans_stats, student_t_test\n",
    "from repo.halo_shape.read_shape_param import halo_bin_stat, read_shape_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import halo files, apply cuts, and extract parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After convergence cut  133637  out of initial  134908  remain.\n",
      "lmda for hrun completed:  129978  halos remain\n",
      "shapecut for hrun completed:  119708  halos remain\n",
      "ID_cut for halo_shape completed:  119708  halos remain\n"
     ]
    }
   ],
   "source": [
    "from repo.halo_shape.read_shape_param import read_shape_param\n",
    "import numpy.lib.recfunctions as rfn\n",
    "\n",
    "filename = 'halo_shape_hruncut_allz.npy'\n",
    "halo_shape = np.load(shapedir+filename)\n",
    "num_bcut = len(halo_shape)\n",
    "\n",
    "#Apply convergence cut\n",
    "conv_cut = np.where(halo_shape['converge']==True)\n",
    "halo_shape = halo_shape[conv_cut]\n",
    "print \"After convergence cut \", len(halo_shape), \" out of initial \", num_bcut, \" remain.\" \n",
    "\n",
    "#Find corresponding richness and mass of halos_ID in hrun, after shape cut\n",
    "filename = homedir + 'data/halo_run/buzzard-0_1.6_y3_run_halos_lambda_chisq_chto_fullhalo_final_chto.fit'\n",
    "hrun_list = fits.open(filename)\n",
    "hrun_data = hrun_list[1].data\n",
    "\n",
    "#First do a lambda cut\n",
    "lmda_cut = np.where((hrun_data['LAMBDA_CHISQ'] >= 5.))\n",
    "hrun_data = hrun_data[lmda_cut]\n",
    "print \"lmda for hrun completed: \", len(hrun_data), \" halos remain\"\n",
    "\n",
    "#Cut for hrun_data\n",
    "shapecut = [ind for (ind, val) in enumerate(hrun_data['HALOID']) if val in halo_shape['halos_ID']]\n",
    "hrun_data = hrun_data[shapecut]\n",
    "print \"shapecut for hrun completed: \", len(hrun_data), \" halos remain\"\n",
    "\n",
    "#Cut for halo_shape\n",
    "ID_cut = [ind for (ind, val) in enumerate(halo_shape['halos_ID']) if val in hrun_data['HALOID']]\n",
    "halo_shape = halo_shape[ID_cut]\n",
    "print \"ID_cut for halo_shape completed: \", len(halo_shape), \" halos remain\"\n",
    "\n",
    "assert len(halo_shape) == len(hrun_data), 'hrun_data and halo_shape don\\'t have equal number of halos'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##NO NEED to match hrun ID with redM. Use just the hrun catalog richness-mass, no matching. \n",
    "\n",
    "#Need to combine with array that has mass, richness sorted by halos_ID. \n",
    "#The matched redM_halorun halos \n",
    "filename = 'redM_halos_hruncut_mcut5e13.npy'\n",
    "matched_halos = np.load(buzzdir +filename)\n",
    "\n",
    "#Convert arrays into record array for easier manipulation\n",
    "matched_halos = matched_halos.view(np.recarray)\n",
    "halo_shape = halo_shape.view(np.recarray)\n",
    "\n",
    "#Sor by ID for cutting out halos with non-convergent IDs, i.e. those not found in halo_shape after convcut\n",
    "shapecut = [ind for (ind, val) in enumerate(matched_halos.halos_ID) if val in halo_shape.halos_ID]\n",
    "\n",
    "#Shape_cut; only retain halos with converged shape\n",
    "matched_halos_shapecut = matched_halos[shapecut]\n",
    "\n",
    "#Add shape parameters to matched_halos array\n",
    "assert len(shape_param) == len(matched_halos_shapecut), \"Shape param and matched_halos have different number of halos\"\n",
    "arrays = [matched_halos_shapecut, shape_param]\n",
    "matched_halos_shapecut = rfn.merge_arrays(arrays, flatten = True, usemask = False)\n",
    "matched_halos_shapecut = matched_halos_shapecut.view(np.recarray)\n",
    "\n",
    "print \"Number of halos after shape cut is \", len(matched_halos_shapecut)\n",
    "print matched_halos_shapecut.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Shorthand name for relevant halo/redM parameters\n",
    "richness= hrun_data.LAMBDA_CHISQ\n",
    "halos_M = hrun_data.M200B\n",
    "halos_ID_shapecut, q, s, cos_i =  read_shape_param(halo_shape, convcut=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Halos Files -- by cos(i) and richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum richness after cuts is  494.7688\n"
     ]
    }
   ],
   "source": [
    "from repo.halo_shape.read_shape_param import halo_bin_stat\n",
    "\n",
    "#Bin by cosine\n",
    "cosi_num_bin = 5\n",
    "cosi_bin_edge = np.linspace(0,1,cosi_num_bin+1)\n",
    "cosi_bins = []\n",
    "for i in range(cosi_num_bin):\n",
    "    cosi_bins.append([cosi_bin_edge[i], cosi_bin_edge[i+1]])\n",
    "    \n",
    "cosi_bins_ind = halo_bin_stat(cos_i, cosi_bins)\n",
    "    \n",
    "#Bin by richness\n",
    "lmda_max = np.max(richness)\n",
    "lmda_bins = [[20,30],[30,50],[50,lmda_max]] #upper limit must match lower limit of next bin\n",
    "num_lmda_bins = len(lmda_bins)\n",
    "lmda_bins_ind = halo_bin_stat(richness, lmda_bins)\n",
    "print 'Maximum richness after cuts is ', lmda_max\n",
    "\n",
    "#Contains all halos. List should be of length with an array that contains all halos.\n",
    "all_ind = [np.arange(len(q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Binning richness by cos_i\n",
    "num_bins = len(cosi_bins)\n",
    "lnM200b_binned = [None]*num_bins\n",
    "lnl_binned = [None]*num_bins\n",
    "\n",
    "lnl = np.log(richness)\n",
    "lnM200b = np.log(halos_M)\n",
    "\n",
    "for i, cosi_bin in enumerate(cosi_bins):\n",
    "    lnM200b_binned[i] = np.log(halos_M[cosi_bins_ind[i]])\n",
    "    lnl_binned[i] = np.log(richness[cosi_bins_ind[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating fake data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For randomly sampling from a pdf. \n",
    "def weighted_choice(seq, weights):\n",
    "    assert len(weights) == len(seq), \"Lengths of seq, weights not equal\"\n",
    "    #assert abs(1. - sum(weights)) < 1e-6\n",
    "    sum_weight = np.sum(weights)\n",
    "    \n",
    "    x = rnd.random()*sum_weight\n",
    "    seq_resamp = np.zeros_like(seq)\n",
    "    for i, _ in enumerate(seq):\n",
    "        x = rnd.random()*sum_weight\n",
    "        for j, elmt in enumerate(seq):\n",
    "            if x <= weights[j]:\n",
    "                seq_resamp[i] = elmt\n",
    "                break\n",
    "            x -= weights[j]\n",
    "    return seq_resamp\n",
    "    \n",
    "#Fake Data\n",
    "#Let lnM sample from P_lnM_Buzzard\n",
    "lnM_num = 1000\n",
    "lnM_lin = np.linspace(13*np.log(10), 15.1*np.log(10), lnM_num)\n",
    "lnM_min = 13*np.log(10); lnM_max = 15.1*np.log(10); num_bins=20\n",
    "lnM_density = redMaPPer_hmf(lnM_lin, lnM_min = lnM_min, lnM_max = lnM_max, num_bins=num_bins)\n",
    "lnM_fake = weighted_choice(lnM_lin, lnM_density)\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(lnM_fake, num_bins)\n",
    "plt.show()\n",
    "\n",
    "A=np.exp(3); B=.7;sig0=0.3\n",
    "mu_lnl=np.log(A)+B*(lnM_fake-14.0*np.log(10.0))\n",
    "var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "lnl=randn(len(lnM_fake))*np.sqrt(var_lnl)+mu_lnl\n",
    "# apply a lambda cut\n",
    "ind=np.where(lnl >  np.log(20))\n",
    "lnl_cut_fake=lnl[ind]\n",
    "lnM_cut_fake=lnM_fake[ind]\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.plot(lnM_cut_fake, np.exp(lnl_cut_fake), marker='o', markersize='0.1', linestyle='None')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Fake Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with Model 1\n",
    "\n",
    "The posteriors found through sampling the fake data is in the ballpark and has good contours but is off in absolute value. \n",
    "\n",
    "| Parameter   |   True   | Found   |\n",
    "|-------------|----------|---------|\n",
    "|  As         |   20.08  |   5.74  |   \n",
    "|  Bs         |   0.5    |  0.677  | \n",
    "|  sig0s      |   0.5    |  0.628  | \n",
    "\n",
    "This is before I matched the hmf of fake data with that used in model. Model2 results are after adjustment and they match well. \n",
    "\n",
    "#### Test with Model 2\n",
    "The posteriors found through sampling the fake data is in the ballpark and has good contours but is off in absolute value. \n",
    "\n",
    "| Parameter   |   True   | Found                  |\n",
    "|-------------|----------|---------               |\n",
    "|  $A_0$         |   22.19  |   22.77 $\\pm$ 0.39   |   \n",
    "|  $A_1$         |   24.53  |   24.21 $\\pm$ 0.40   |   \n",
    "|  $A_2$         |   27.11  |   27.59 $\\pm$ 0.42  |   \n",
    "|  $A_3$         |   29.96  |   30.21 $\\pm$ 0.43  |   \n",
    "|  $A_4$         |   33.11  |   32.59 $\\pm$ 0.44  |   \n",
    "|  Bs         |   0.6    |  0.59 $\\pm$ 0.01       | \n",
    "|  sig0s      |   0.3    |  0.30 $\\pm$ 0.01       | \n",
    "\n",
    "Results agree. \n",
    "\n",
    "#### Test with model 3\n",
    "This model varies A only, and inputs the best fit B and sig0 found from the maximum posterior from model2. \n",
    "Unlike model2, this model input does not allow input of lnl and lnM from different bins. To find posterior for different\n",
    "bins need to call the model each time, creating a MCMC folder for each bin. \n",
    "\n",
    "\n",
    "| Parameter   |   True   | Found                  |\n",
    "|-------------|----------|---------               |\n",
    "|  $A$         |   20.09  |   20.08 $\\pm$ 0.37   |   \n",
    "\n",
    "Results agree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Template for richness-mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a linear relation in richness-mass in the log-log plane, and with a log-normal scatter. Free parameters are A the intercept, B the slope, and sig0 the instrinsic scatter.\n",
    "\n",
    "The truncated Gaussian at $\\lambda = 20$ is normalized with the mass function from the random halo catalog in the Buzzard simulations. \n",
    "\n",
    "The linear relation between richness and mass is\n",
    "$$\n",
    "\\mu_{\\log(\\lambda)} = \\log{A} + B*(\\log{M} - \\log{10^{14}})\n",
    "$$\n",
    "\n",
    "with instrinsic scatter\n",
    "$$\n",
    "\\sigma^2(\\log{\\lambda}) = \\sigma_0^2 + \\frac{\\exp{\\mu}-1}{2\\exp{\\mu}}.\n",
    "$$\n",
    "\n",
    "The posterior probability is \n",
    "$$\n",
    "P(A,B,\\sigma|\\lambda, M) = \\frac{1}{N(A,B,\\sigma, M)}P(\\lambda, M | A, B, \\sigma) P (A, B, \\sigma),\n",
    "$$\n",
    "\n",
    "with normalization factor\n",
    "$$\n",
    "N(A, B, \\sigma, M) = \\int dM \\int_{20}^{+\\infty} d \\lambda P(\\lambda| M, A, B, \\sigma) P(M)\n",
    "= \\int dM(0.5 - 0.5 \\mathrm{erf}\\big(\\frac{\\mathrm{ln} 20 - \\mu{(\\mathrm{ln} \\lambda)}}{\\sqrt{2(\\sigma_0^2+ \\frac{\\mathrm{exp} ( \\mu{(\\mathrm{ln} \\lambda)})-1}{\\mathrm{exp} ( 2\\mu{(\\mathrm{ln} \\lambda)})})}} \\big) P(M).\n",
    "$$\n",
    "\n",
    "$P(M)$ is sampled from the randomly selected halo (see code tools.halo_mass_template) and integration is done by tabulating P(M) into 100 bins. \n",
    "\n",
    "**See lmda_cosi_model.py for explanation of different models**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating MCMC Chains with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapecut for hrun completed in halo_mass_template\n"
     ]
    }
   ],
   "source": [
    "from repo.richness_mass.lmda_cosi_model import make_model, make_model2, make_model3 #this takes a while because of tab hmf\n",
    "from pymc import *\n",
    "from pymc import DiscreteUniform, Normal, uniform_like, TruncatedNormal\n",
    "from pymc import Metropolis\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from chainconsumer import ChainConsumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MCMC chain setup\n",
    "num=100\n",
    "n_iter=num*3000\n",
    "n_burn=num*500\n",
    "n_thin=num    \n",
    "\n",
    "#data input\n",
    "\n",
    "mcmc_filestr = range(len(cosi_bins))\n",
    "#For binned by cos_i\n",
    "for i in mcmc_filestr:\n",
    "    print '\\n Bin number ', i\n",
    "    mcmc_folder = tpltdir  + 'p_lmda_cosi_'+str(mcmc_filestr[i])+'_model1'\n",
    "    cosi_bin_ind = cosi_bins_ind[i]\n",
    "    M=pymc.Model(make_model(lnl_binned[i], lnM200b_binned[i]))\n",
    "    mc=MCMC(M, db='txt', dbname=mcmc_folder)\n",
    "    mc.sample(iter=n_iter, burn=n_burn, thin=n_thin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### For model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [--                7%                  ] 22659 of 300000 complete in 1360.9 sec"
     ]
    }
   ],
   "source": [
    "#This is the data input format for model2\n",
    "#MCMC chain setup\n",
    "num=100\n",
    "n_iter=num*3000\n",
    "n_burn=num*500\n",
    "n_thin=num     \n",
    "\n",
    "#For different bins. Vary A but keep B and sigma fixed. \n",
    "mcmc_folder = tpltdir  + 'p_lmda_cosi_' +'all_'+'model2'\n",
    "M=pymc.Model(make_model2(lnl_binned, lnM200b_binned)) #Use make_model2 for binned data. \n",
    "mc=MCMC(M, db='txt', dbname=mcmc_folder)\n",
    "mc.sample(iter=n_iter, burn=n_burn, thin=n_thin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to input the global B, sigma0 found from model2. Model 3 only makes sense after running and inputting the posterior\n",
    "#from model2\n",
    "c = ChainConsumer() #contains multiple chains across different models\n",
    "mcmc_folder = tpltdir + 'p_lmda_cosi_'+'all'+'_model2'\n",
    "\n",
    "for i in range(0):\n",
    "    cosi_bin_min = cosi_bins[i][0]; cosi_bin_max = cosi_bins[i][1]\n",
    "    As=np.genfromtxt(mcmc_folder+'/Chain_0/A_{}.txt'.format(i))\n",
    "    Bs=np.genfromtxt(mcmc_folder+'/Chain_0/B.txt')\n",
    "    sig0s=np.genfromtxt(mcmc_folder+'/Chain_0/sigma0.txt')\n",
    "\n",
    "    # plot the parameter constraints\n",
    "\n",
    "    data=np.vstack( (As, Bs, sig0s) ).T\n",
    "    c.add_chain(data, parameters=[r\"$A$\", r\"$B$\", r\"$\\sigma_0$\"], \\\n",
    "                name=r'Template for $cos(i)\\in[%.1f, %.1f)$'%(cosi_bin_min, cosi_bin_max))\n",
    "\n",
    "    c.configure(statistics=\"max_shortest\")\n",
    "\n",
    "c_posterior = c.analysis.get_summary()    \n",
    "B_post_model2 = c_posterior[\"$B$\"][1] #Find max likelihood value\n",
    "sig0_post_model2 = c_posterior[\"$\\sigma_0$\"][1] #Find max likelihood value\n",
    "    \n",
    "    \n",
    "B_allfit =  B_post_model2       #stat_cosi[1][0,0] #Take from model2\n",
    "sigma0_allfit = sig0_post_model2    #stat_cosi[2][0,0] #Taken from model2\n",
    "print B_allfit, sigma0_allfit\n",
    "\n",
    "num=100\n",
    "n_iter=num*3000\n",
    "n_burn=num*500\n",
    "n_thin=num   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For different cosine bins\n",
    "mcmc_filestr=range(cosi_num_bin)\n",
    "for i in mcmc_filestr:\n",
    "    print '\\n Bin number ', i\n",
    "    mcmc_folder = tpltdir  + 'p_lmda_cosi_'+str(mcmc_filestr[i])+'_model3'\n",
    "    cosi_bin_ind = cosi_bins_ind[i]\n",
    "    M=pymc.Model(make_model3(lnl_binned[i], lnM200b_binned[i], B_allfit, sigma0_allfit))\n",
    "    mc=MCMC(M, db='txt', dbname=mcmc_folder)\n",
    "    mc.sample(iter=n_iter, burn=n_burn, thin=n_thin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combined for model3\n",
    "mcmc_folder = datadir + 'p_lmda_cosi_'+'all_'+'model3'\n",
    "M=pymc.Model(make_model3(lnl, lnM200b, B_allfit, sigma0_allfit))\n",
    "mc=MCMC(M, db='txt', dbname=mcmc_folder)\n",
    "mc.sample(iter=n_iter, burn=n_burn, thin=n_thin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "c = ChainConsumer() #contains multiple chains across different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cosi_bins)):\n",
    "\n",
    "    cosi_bin_min = cosi_bins[i][0]; cosi_bin_max = cosi_bins[i][1]\n",
    "    mcmc_folder = tpltdir + 'p_lmda_cosi_'+str(i)+'_model1'\n",
    "        \n",
    "    As=np.genfromtxt(mcmc_folder+'/Chain_0/A.txt')\n",
    "    Bs=np.genfromtxt(mcmc_folder+'/Chain_0/B.txt')\n",
    "    sig0s=np.genfromtxt(mcmc_folder+'/Chain_0/sigma0.txt')\n",
    "\n",
    "    # plot the parameter constraints\n",
    "    data=np.vstack( (As, Bs, sig0s) ).T\n",
    "    c.add_chain(data, parameters=[r\"$A$\", r\"$B$\", r\"$\\sigma_0$\"], \\\n",
    "                name=r'Model1 for $cos(i)\\in[%.1f, %.1f)$'%(cosi_bin_min, cosi_bin_max))\n",
    "    c.configure(statistics=\"max_shortest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc_folder = tpltdir + 'p_lmda_cosi_'+'all'+'_model2'\n",
    "\n",
    "for i in range(len(cosi_bins)):\n",
    "    cosi_bin_min = cosi_bins[i][0]; cosi_bin_max = cosi_bins[i][1]\n",
    "    As=np.genfromtxt(mcmc_folder+'/Chain_0/A_{}.txt'.format(i))\n",
    "    Bs=np.genfromtxt(mcmc_folder+'/Chain_0/B.txt')\n",
    "    sig0s=np.genfromtxt(mcmc_folder+'/Chain_0/sigma0.txt')\n",
    "\n",
    "    # plot the parameter constraints\n",
    "\n",
    "    data=np.vstack( (As, Bs, sig0s) ).T\n",
    "    c.add_chain(data, parameters=[r\"$A$\", r\"$B$\", r\"$\\sigma_0$\"], \\\n",
    "                name=r'Template for $cos(i)\\in[%.1f, %.1f)$'%(cosi_bin_min, cosi_bin_max))\n",
    "\n",
    "    c.configure(statistics=\"max_shortest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(cosi_bins)):\n",
    "    mcmc_folder = tpltdir + 'p_lmda_cosi_'+str(i)+'_model3'\n",
    "    As = np.genfromtxt(mcmc_folder+'/Chain_0/A.txt')\n",
    "    data = As\n",
    "    c.add_chain(data, parameters=[r\"$A$\"], name=r'Template for $cos(i)\\in[%.1f, %.1f)$'%(cosi_bin_min, cosi_bin_max))\n",
    "    c.configure(statistics=\"max_shortest\")\n",
    "    \n",
    "#Combined\n",
    "mcmc_folder = tpltdir + 'p_lmda_cosi_'+'all'+'_model3'\n",
    "As = np.genfromtxt(mcmc_folder+'/Chain_0/A.txt')\n",
    "data = As\n",
    "c.add_chain(data, parameters=[r\"$A$\"], name=r'Model3 for $cos(i)\\in[%.1f, %.1f)$'%(cosi_bin_min, cosi_bin_max))\n",
    "c.configure(statistics=\"max_shortest\")\n",
    "#c.plot(filename=\"test1.png\", figsize=\"column\", truth=[A, B, sig0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the posterior likelihood statistics\n",
    "\n",
    "The Chainconsumer object c contains multiple chains read from the section \"Generating MCMC chain from data posteriors\"\n",
    "\n",
    "Chains 0-4 are the cosine bins in model1. \n",
    "\n",
    "Chain 5 are the fit from model2. The sigma and B parameters should be the same across these chains. \n",
    "\n",
    "Chains 6-10 are the cosine fit from model3 -- this is one where vary A only and take best fit B,sigma from model2. \n",
    "\n",
    "Chain 11 is the combined fit for model3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A makeshift script for testing model. Need to systematize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting posterior for B\n",
    "c_posterior = c.analysis.get_summary()\n",
    "\n",
    "lnA_post_model2 = np.zeros((5,3)) #Universal fit\n",
    "B_post_model2 = np.zeros((1,3)) #Univesal fit across cosine bins\n",
    "sig0_post_model2 = np.zeros((1,3))\n",
    "\n",
    "for i in range(5):\n",
    "    lnA_post_model2[i] = c_posterior[i][\"$A$\"]\n",
    "    print \"B \", c_posterior[i][\"$B$\"]\n",
    "    print \"A \",  c_posterior[i][\"$A$\"]\n",
    "    print \"sig0 \", c_posterior[i][\"$\\sigma_0$\"]\n",
    "    print '\\n'\n",
    "    \n",
    "B_post_model2 = c_posterior[0][\"$B$\"]\n",
    "sig0_post_model2 = c_posterior[0][\"$\\sigma_0$\"]\n",
    "\n",
    "print B_post_model2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the trendlines for different bins\n",
    "fig, axs = plt.subplots(1 ,1, tight_layout=True, figsize=(6,4))\n",
    "axs.plot(halos_M, richness, 'k.', markersize=1)\n",
    "\n",
    "lnM_range = np.arange(31,35,0.1)\n",
    "B_cosi_maxL = B_post_model2[1]; sig0_cosi_maxL = sig0_post_model2[1]\n",
    "for i, cosi_bin in enumerate(cosi_bins):\n",
    "    cosi_bin_min = cosi_bin[0]; cosi_bin_max = cosi_bin[1]\n",
    "    lnA_cosi_maxL = lnA_post_model2[i,1]; \n",
    "    mu_lnl_model = lnA_cosi_maxL + B_cosi_maxL*(lnM_range-np.log(10)*14)\n",
    "    sig_lnl_model=np.sqrt(sig0_cosi_maxL**2+(np.exp(mu_lnl_model)-1)/(np.exp(2*mu_lnl_model)))\n",
    "    axs.plot(10**(lnM_range/np.log(10)), np.exp(mu_lnl_model), linewidth=2, linestyle='dashed', \\\n",
    "        label='$\\cos(i) \\in [{:.1f}, {:.1f})$'.format(cosi_bin_min,cosi_bin_max))\n",
    "\n",
    "axs.axhline(20, linestyle='dotted')\n",
    "axs.set_yscale('log')\n",
    "axs.set_xscale('log')\n",
    "axs.legend(fontsize=12)\n",
    "axs.set_xlabel('Mass $(M_\\odot)$',fontsize=14)\n",
    "axs.set_ylabel('Richness $(\\lambda)$',fontsize=14)\n",
    "axs.set_ylim((15,100))\n",
    "#axs.axvspan(2.05e14, 2.13e14, alpha=0.5)\n",
    "#axs.axhline(40)\n",
    "#plt.savefig('mass_richness_cosibinned_60718.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Posterior. For each paramater array contains 3 indexes -- low, max posterior, and high range. \n",
    "'''\n",
    "funk = c_posterior[i][\"$A$\"] reads the A parameter statistic of the i-th chain. \n",
    "The statistic is read as array of min, mean, max values of statistic (e.g. max_shhortest),\n",
    "so that funk[1], for instance,  is the mean value of A in the ith chain. \n",
    "'''\n",
    "\n",
    "c_posterior = c.analysis.get_summary()\n",
    "\n",
    "#x parameters are the mean of each cosi_bin\n",
    "x_pos = np.zeros(len(cosi_bins))\n",
    "for i, cosi_bin in enumerate(cosi_bins):\n",
    "    cosi_bin_min = cosi_bin[0]; cosi_bin_max = cosi_bin[1]\n",
    "    x_pos[i] = (cosi_bin_max+cosi_bin_min)/2.\n",
    "#print x_pos\n",
    "\n",
    "#Posterior likelihoods\n",
    "lnA_post_model1 = np.zeros((len(cosi_bins),3))\n",
    "B_post_model1 = np.zeros((len(cosi_bins),3))\n",
    "sig0_post_model1 = np.zeros((len(cosi_bins),3))\n",
    "\n",
    "B_post_model2 = np.zeros((1,3)) #Universal fit\n",
    "sig0_post_model2 = np.zeros((1,3)) #Univesal fit across cosine bins\n",
    "\n",
    "lnA_post_model3 = np.zeros((len(cosi_bins)+1,3)) #A plus the combined fit\n",
    "\n",
    "\n",
    "#For model1\n",
    "for i in range(0,5):\n",
    "    lnA_post_model1[i] = np.log(c_posterior[i][\"$A$\"])\n",
    "    B_post_model1[i] = c_posterior[i][\"$B$\"]\n",
    "    sig0_post_model1[i] = c_posterior[i][\"$\\sigma_0$\"]\n",
    "    \n",
    "#B, sigma0 for model2\n",
    "for i in range(5,6):\n",
    "    B_post_model2[i-5] = c_posterior[i][\"$B$\"]\n",
    "    sig0_post_model2[i-5] = c_posterior[i][\"$\\sigma_0$\"]\n",
    "    \n",
    "#A for model3\n",
    "for i in range(6,12):\n",
    "    lnA_post_model3[i-6] = np.log(c_posterior[i][\"$A$\"])\n",
    "    \n",
    "\n",
    "#Plotting the posteriors #########################################################\n",
    "#Plotting posterior for lnA\n",
    "fig, axs = plt.subplots(1, 3, tight_layout=True, figsize=(8,3))\n",
    "subtitles = [r'$\\log(A)$', r'$B$', r'$\\sigma_0$']\n",
    "stat_name = [\"$A$\", \"$B$\", \"$\\sigma_0$\"]\n",
    "\n",
    "axs[0].errorbar(x_pos, lnA_post_model1[:,1], \\\n",
    "                yerr=[lnA_post_model1[:,1]-lnA_post_model1[:,0], lnA_post_model1[:,2]-lnA_post_model1[:,1]], \\\n",
    "                linewidth=0.6, marker='o',markersize=3, label='3-param model')\n",
    "\n",
    "axs[0].errorbar(x_pos, lnA_post_model3[:-1,1], \\\n",
    "                yerr=[lnA_post_model3[:-1,1]-lnA_post_model3[:-1,0], lnA_post_model3[:-1,2]-lnA_post_model3[:-1,1]], \\\n",
    "                linewidth=0.6, marker='o', markersize=3, label='1-param model')    \n",
    "\n",
    "#Plotting posterior for B\n",
    "\n",
    "axs[1].errorbar(x_pos, B_post_model1[:,1], \\\n",
    "                yerr=[B_post_model1[:,1]-B_post_model1[:,0], B_post_model1[:,2]-B_post_model1[:,1]], \\\n",
    "                linewidth=0.6, marker='o',markersize=5, label='3-param model')\n",
    "\n",
    "xband = np.linspace(0,1,5)\n",
    "axs[1].fill_between(xband, B_post_model2[:,0], B_post_model2[:,2], \\\n",
    "                facecolor='orange', interpolate=False, label='1-param model')  \n",
    "\n",
    "#Plotting posterior for sigma0\n",
    "axs[2].errorbar(x_pos, sig0_post_model1[:,1], \\\n",
    "                yerr=[sig0_post_model1[:,1]-sig0_post_model1[:,0], sig0_post_model1[:,2]-sig0_post_model1[:,1]], \\\n",
    "                linewidth=0.6, marker='o',markersize=5, label='3-param model')\n",
    "\n",
    "axs[2].fill_between(xband, sig0_post_model2[:,0], sig0_post_model2[:,2], \\\n",
    "                facecolor='orange', interpolate=False, label='1-param model')  \n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].set_xlim((0,1))\n",
    "    axs[i].set_xticks(x_pos)\n",
    "    axs[i].set_ylabel(subtitles[i], size=14)\n",
    "    axs[i].set_xlabel(r'$\\cos(i)$', size=14) \n",
    "\n",
    "axs[2].set_xlabel(r'$\\cos(i)$', size=14) \n",
    "axs[0].legend(fontsize=10)\n",
    "#plt.savefig('richness_mass_modelparams_cosibinned_060718.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the trendlines for different bins\n",
    "fig, axs = plt.subplots(1 ,1, tight_layout=True, figsize=(6,4))\n",
    "axs.plot(halos_M, richness, 'k.', markersize=1)\n",
    "\n",
    "lnM_range = np.arange(31,35,0.1)\n",
    "B_cosi_maxL = B_post_model2[0,1]; sig0_cosi_maxL = sig0_post_model2[0,1]\n",
    "for i, cosi_bin in enumerate(cosi_bins):\n",
    "    cosi_bin_min = cosi_bin[0]; cosi_bin_max = cosi_bin[1]\n",
    "    lnA_cosi_maxL = lnA_post_model3[i,1]; \n",
    "    mu_lnl_model = lnA_cosi_maxL + B_cosi_maxL*(lnM_range-np.log(10)*14)\n",
    "    sig_lnl_model=np.sqrt(sig0_cosi_maxL**2+(np.exp(mu_lnl_model)-1)/(np.exp(2*mu_lnl_model)))\n",
    "    axs.plot(10**(lnM_range/np.log(10)), np.exp(mu_lnl_model), linewidth=2, linestyle='dashed', \\\n",
    "        label='$\\cos(i) \\in [{:.1f}, {:.1f})$'.format(cosi_bin_min,cosi_bin_max))\n",
    "             \n",
    "#for all data points    \n",
    "lnA_cosi_maxL = lnA_post_model3[-1,1]; B_cosi_maxL = B_post_model2[0,1]; sig0_cosi_maxL = sig0_post_model2[0,1]\n",
    "mu_lnl_model = lnA_cosi_maxL + B_cosi_maxL*(lnM_range-np.log(10)*14)\n",
    "sig_lnl_model=np.sqrt(sig0_cosi_maxL**2+(np.exp(mu_lnl_model)-1)/(np.exp(2*mu_lnl_model)))\n",
    "axs.plot(10**(lnM_range/np.log(10)), np.exp(mu_lnl_model), \\\n",
    "            label='Combined', linewidth=2)\n",
    "axs.axhline(20, linestyle='dotted')\n",
    "axs.set_yscale('log')\n",
    "axs.set_xscale('log')\n",
    "axs.legend(fontsize=12)\n",
    "axs.set_xlabel('Mass $(M_\\odot)$',fontsize=14)\n",
    "axs.set_ylabel('Richness $(\\lambda)$',fontsize=14)\n",
    "axs.set_ylim((15,100))\n",
    "#axs.axvspan(2.05e14, 2.13e14, alpha=0.5)\n",
    "#axs.axhline(40)\n",
    "#plt.savefig('mass_richness_cosibinned_60718.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generating BIC for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates the BIC for a given model.\n",
    "D: mean log(x|theta) across posterior distribution theta.\n",
    "k: number of free parameters\n",
    "N: number of data points\n",
    "'''\n",
    "\n",
    "def calc_bic(D,k,N):\n",
    "    return -2*D + k*np.log(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(cosi_bins)):\n",
    "    #For model 3\n",
    "    mcmc_folder = tpltdir + 'p_lmda_cosi_'+str(i)+'_model3'       \n",
    "    deviance = np.genfromtxt(mcmc_folder+'/Chain_0/deviance.txt')\n",
    "    bic_model3 = calc_bic(np.mean(deviance), 1, len(richness[cosi_bins_ind[i]]))\n",
    "    print \"BIC in cosi bin \", i, \"for model 3 is \", bic_model3\n",
    "    \n",
    "    #For model 1\n",
    "    mcmc_folder = tpltdir + 'p_lmda_cosi_'+str(i)+'_model1'       \n",
    "    As=np.genfromtxt(mcmc_folder+'/Chain_0/A.txt')\n",
    "    deviance = np.genfromtxt(mcmc_folder+'/Chain_0/deviance.txt')\n",
    "    bic_model3 = calc_bic(np.mean(deviance), 3, len(richness[cosi_bins_ind[i]]))\n",
    "    print \"BIC in cosi bin \", i, \"for model 1 is \", bic_model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
