{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYMC models for richness-mass relation\n",
    "### Zhuowen Zhang\n",
    "### Created Aug 27, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import pyplot and set some parameters to make plots prettier\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.plot_utils import plot_pretty\n",
    "plot_pretty()\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/zzbenjamin94/Desktop/Astronomy/Research/DES_Galaxy_Cluster')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tools.setup.setup import tools_home_dir, home_dir\n",
    "import pyfits\n",
    "shapedir = home_dir()+'output/buzzard/halo_shape/'\n",
    "tpltdir = home_dir() + 'output/lmda_cosi_chains/'\n",
    "toolsdir = tools_home_dir()\n",
    "homedir = home_dir()\n",
    "\n",
    "import astropy.io.fits as pyfits\n",
    "import ConfigParser\n",
    "import healpy as hp\n",
    "import treecorr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for richness-mass from the pymc package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a linear relation in richness-mass in the log-log plane, and with a log-normal scatter. Free parameters are A the intercept, B the slope, and sig0 the instrinsic scatter.\n",
    "\n",
    "The truncated Gaussian at $\\lambda = 20$ is normalized with the mass function from the random halo catalog in the Buzzard simulations. \n",
    "\n",
    "The linear relation between richness and mass is\n",
    "$$\n",
    "\\mu_{\\log(\\lambda)} = \\log{A} + B*(\\log{M} - \\log{10^{14}})\n",
    "$$\n",
    "\n",
    "with instrinsic scatter\n",
    "$$\n",
    "\\sigma^2(\\log{\\lambda}) = \\sigma_0^2 + \\frac{\\exp{\\mu}-1}{2\\exp{\\mu}}.\n",
    "$$\n",
    "\n",
    "The posterior probability is \n",
    "$$\n",
    "P(A,B,\\sigma|\\lambda, M) = \\frac{1}{N(A,B,\\sigma, M)}P(\\lambda, M | A, B, \\sigma) P (A, B, \\sigma),\n",
    "$$\n",
    "\n",
    "with normalization factor\n",
    "$$\n",
    "N(A, B, \\sigma, M) = \\int dM \\int_{20}^{+\\infty} d \\lambda P(\\lambda| M, A, B, \\sigma) P(M)\n",
    "= \\int dM(0.5 - 0.5 \\mathrm{erf}\\big(\\frac{\\mathrm{ln} 20 - \\mu{(\\mathrm{ln} \\lambda)}}{\\sqrt{2(\\sigma_0^2+ \\frac{\\mathrm{exp} ( \\mu{(\\mathrm{ln} \\lambda)})-1}{\\mathrm{exp} ( 2\\mu{(\\mathrm{ln} \\lambda)})})}} \\big) P(M).\n",
    "$$\n",
    "\n",
    "$P(M)$ is sampled from the randomly selected halo (see code tools.halo_mass_template) and integration is done by tabulating P(M) into 100 bins. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "Find global A, B, and sigma0 across all cosine bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(lnls, lnms):\n",
    "    A=Uniform('A', lower=0.1, upper=100 )\n",
    "    B=Uniform('B', lower=0.0001, upper=10 )\n",
    "    sig0=Uniform('sigma0', lower=0.001, upper=10.0 )   \n",
    "    \n",
    "    #Halo mass function\n",
    "    lnM_min = 13*np.log(10); lnM_max = 15.1*np.log(10)\n",
    "    lnM = np.linspace(lnM_min, lnM_max, 1000)\n",
    "    lnM_density = redMaPPer_hmf(lnM, lnM_min=lnM_min, lnM_max = lnM_max)\n",
    "    delta_lnM = lnM[1]-lnM[0]\n",
    "    \n",
    "    #Use table to approximate integration. Speed things up\n",
    "    def norm_20_tab(A,B,sig0):         \n",
    "        mu_lnl=np.log(A)+B*(lnM-14.0*np.log(10.0)) \n",
    "        var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "\n",
    "        norm_20 = np.sum((0.5-0.5*erf((np.log(20) - mu_lnl)/np.sqrt(2.0*var_lnl)))*lnM_density*delta_lnM)\n",
    "        return norm_20\n",
    "\n",
    "    @pymc.stochastic(observed=True, plot=False)\n",
    "    def log_prob(value=0, A=A, B=B, sig0=sig0):       \n",
    "        mu_lnl=np.log(A)+B*(lnms-14.0*np.log(10.0)) \n",
    "        var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "\n",
    "        norm_20 = norm_20_tab(A,B,sig0)\n",
    "        log_prs=-0.5*(lnls-mu_lnl)**2/var_lnl -0.5*np.log(var_lnl) - np.log(norm_20) \n",
    "\n",
    "        tot_logprob=np.sum(log_prs)\n",
    "        return tot_logprob\n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model 2\n",
    "This model varies A across different cosine bins and finds a global fit for B, Sigma0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_model2(lnls, lnms):\n",
    "    #Extract number of bins\n",
    "    assert len(lnls)==len(lnms), \"Number of bins different for lnls and lnms\"\n",
    "    num_bins = len(lnls)\n",
    "    \n",
    "    #Vary A across bins but keep B, Sigma the same across bins\n",
    "    A = [None]*num_bins\n",
    "    A_0 =Uniform('A_{}'.format(0), lower=0.1, upper=100)\n",
    "    A_1 =Uniform('A_{}'.format(1), lower=0.1, upper=100)\n",
    "    A_2 =Uniform('A_{}'.format(2), lower=0.1, upper=100)\n",
    "    A_3 =Uniform('A_{}'.format(3), lower=0.1, upper=100)\n",
    "    A_4 =Uniform('A_{}'.format(4), lower=0.1, upper=100)\n",
    "    A[0]=A_0; A[1]=A_1; A[2]=A_2; A[3]=A_3; A[4]=A_4\n",
    "    \n",
    "    #The any() function overwritten by PYMC. Does not work\n",
    "    assert None not in A, \"Number of A_i do not match size of A\" #Equiv to not any(x is None for x in A)\n",
    "    \n",
    "    B=Uniform('B', lower=0.0001, upper=10 )\n",
    "    sig0=Uniform('sigma0', lower=0.001, upper=10.0 )   \n",
    "    \n",
    "    #Halo mass function\n",
    "    lnM_min = 13*np.log(10); lnM_max = 15.1*np.log(10)\n",
    "    lnM_tab = np.linspace(lnM_min, lnM_max, 1000); delta_lnM = lnM_tab[1]-lnM_tab[0]\n",
    "    lnM_density = redMaPPer_hmf(lnM_tab)\n",
    "    \n",
    "    #Use table to approximate integration. Speed things up\n",
    "    def norm_20_tab(A_i,B,sig0):       \n",
    "        mu_lnl=np.log(A_i)+B*(lnM_tab-14.0*np.log(10.0)) \n",
    "        var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "        norm_20 = np.sum((0.5-0.5*erf((np.log(20) - mu_lnl)/np.sqrt(2.0*var_lnl)))*lnM_density*delta_lnM)\n",
    "        return norm_20\n",
    "\n",
    "    @pymc.stochastic(observed=True, plot=False)\n",
    "    def log_prob(value=0, A=A, B=B, sig0=sig0):      \n",
    "        tot_logprob = 0\n",
    "        for i in range(num_bins):\n",
    "            mu_lnl=np.log(A[i])+B*(lnms[i]-14.0*np.log(10.0)) #changed May 1, 2018\n",
    "            var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "            norm_20 = norm_20_tab(A[i],B,sig0)\n",
    "            log_prs=-0.5*(lnls[i]-mu_lnl)**2/var_lnl -0.5*np.log(var_lnl) - np.log(norm_20) \n",
    "            tot_logprob += np.sum(log_prs)\n",
    "            \n",
    "        return tot_logprob\n",
    "    \n",
    "    return A_0, A_1, A_2, A_3, A_4, B, sig0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "This models varies A only, and inputs the best fit B and sig0 found from the maximum posterior from make_model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model3(lnls, lnms, B, sig0):\n",
    "    A=Uniform('A', lower=0.1, upper=100 )\n",
    "    \n",
    "    #Halo mass function\n",
    "    lnM_min = 13*np.log(10); lnM_max = 15.1*np.log(10)\n",
    "    lnM = np.linspace(lnM_min, lnM_max, 1000)\n",
    "    lnM_density = redMaPPer_hmf(lnM, lnM_min=lnM_min, lnM_max = lnM_max)\n",
    "    delta_lnM = lnM[1]-lnM[0]\n",
    "   \n",
    "    #Use table to approximate integration. Speed things up\n",
    "    def norm_20_tab(A,B,sig0):         \n",
    "        mu_lnl=np.log(A)+B*(lnM-14.0*np.log(10.0)) \n",
    "        var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "\n",
    "        norm_20 = np.sum((0.5-0.5*erf((np.log(20) - mu_lnl)/np.sqrt(2.0*var_lnl)))*lnM_density*delta_lnM)\n",
    "        return norm_20\n",
    "\n",
    "    @pymc.stochastic(observed=True, plot=False)\n",
    "    def log_prob(value=0, A=A, B=B, sig0=sig0):\n",
    "        lnM_min = 13*np.log(10); lnM_max = 15.1*np.log(10)\n",
    "        mu_lnl=np.log(A)+B*(lnms-14.0*np.log(10.0)) #changed May 1, 2018\n",
    "        var_lnl=sig0**2+(np.exp(mu_lnl)-1)/(np.exp(2*mu_lnl))\n",
    "\n",
    "        norm_20 = norm_20_tab(A,B,sig0)\n",
    "        log_prs=-0.5*(lnls-mu_lnl)**2/var_lnl -0.5*np.log(var_lnl) - np.log(norm_20) \n",
    "\n",
    "        tot_logprob=np.sum(log_prs)\n",
    "        return tot_logprob\n",
    "    return locals()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
